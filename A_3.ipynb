{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a9ce2c-5ff0-4fed-a00f-de79c30b366a",
   "metadata": {},
   "source": [
    "**Assingment 3**<br>\n",
    "**Akbar Abdurakhmonov**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15bec938-1d43-43f6-b89d-60383a873e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [5, 9],\n",
    "    [-2, 3],\n",
    "    [4, 8],\n",
    "    [3, -2],\n",
    "    [-3, -7]\n",
    "]\n",
    "\n",
    "y = [16, 1, 14, 21, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a54802af-5aad-444e-b010-6443536030d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y hat list: [127, 32, 112, 7, -73]\n"
     ]
    }
   ],
   "source": [
    "w = [5, 10, 12]\n",
    "\n",
    "def predict(w, X):\n",
    "    y_hat = []\n",
    "    for i in range(len(X)):\n",
    "        p_hat = w[0] * X[i][0] + w[1] * X[i][1] + w[2]\n",
    "        y_hat.append(p_hat)\n",
    "    return y_hat\n",
    "\n",
    "predicted = predict(w, X)\n",
    "print(\"Y hat list:\", predicted) #printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23dd8402-bffc-40e1-8d10-7f0e50d0fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 76.99740255359268\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(X, y, w):\n",
    "    # Use the 'predict' function to get predictions\n",
    "    y_hat = predict(w, X)\n",
    "    \n",
    "    # Calculate the mean square error\n",
    "    mse = np.mean([(pred - label) ** 2 for pred, label in zip(y_hat, y)])\n",
    "    \n",
    "    # Return the root mean square error\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "    \n",
    "error = loss(X, y, w)\n",
    "print(\"RMSE:\", error) #printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7f83416-b8ca-4216-b855-258d990d0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: [2.8209045246399, 6.418399656112683, 0.37664165425610463]\n"
     ]
    }
   ],
   "source": [
    "def gradient(X, y, w, delta=0.001):\n",
    "    g = []\n",
    "    loss_0 = loss(X, y, w)\n",
    "    for i in range(len(w)):\n",
    "        w_temp = w.copy()\n",
    "        w_temp[i] += delta\n",
    "        loss_1 = loss(X, y, w_temp) #calculating the loss\n",
    "        \n",
    "        g_component = (loss_1 - loss_0) / delta\n",
    "        g.append(g_component)\n",
    "    return g\n",
    "\n",
    "\n",
    "g_list = gradient(X, y, w)\n",
    "print(\"Gradient:\", g_list) #printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2caa7b8-7448-4ab7-bdfc-59f2fb0eb7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights: [4.71790954753601, 9.358160034388732, 11.96233583457439]\n"
     ]
    }
   ],
   "source": [
    "def update(w, learning_rate=0.1):\n",
    "    g = gradient(X, y, w)\n",
    "    for i in range(len(w)):\n",
    "        w[i] -= learning_rate * g[i] \n",
    "    return w\n",
    "\n",
    "updated_weights = update(w)\n",
    "print(\"Updated Weights:\", updated_weights) #printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af283096-ab1d-4236-ab9b-c2a0614a356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.428035701729321\n",
      "Update: [1.029696652890543, 0.7495845712021989, 1.0647504945245458]\n",
      "New Loss 10.835387784113383\n",
      "Loss v2: 20.33715811021786\n",
      "Update v2 [-0.6833445794944595, -0.5535793935616198, 0.07670587062875711]\n",
      "New Loss v2: 17.434249288593527\n"
     ]
    }
   ],
   "source": [
    "w = [1, 1, 1]\n",
    "\n",
    "loss_new = loss(X, y, w)\n",
    "print(\"Loss:\", loss_new)\n",
    "\n",
    "update_w = update(w)\n",
    "print(\"Update:\", update_w)\n",
    "\n",
    "loss_w = loss(X, y, update_w)\n",
    "print(\"New Loss\", loss_w)\n",
    "\n",
    "\n",
    "w = [-1, -1, 0] #new values for w\n",
    "\n",
    "loss_new_2 = loss(X, y, w)\n",
    "print(\"Loss v2:\", loss_new_2)\n",
    "\n",
    "update_w_2 = update(w)\n",
    "print(\"Update v2\", update_w_2)\n",
    "\n",
    "loss_w_2 = loss(X, y, update_w_2)\n",
    "print(\"New Loss v2:\", loss_w_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7299a-0d69-4423-9898-9d358716ccc2",
   "metadata": {},
   "source": [
    "**Question:** Did the loss get lower after the parameters were updated? Does this mean the code is working properly? <br>\n",
    "**Answer:** Yes, in both cases the loss were lower after the parameters were updated. This means that the code is functioning properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e27b9cbe-e5ea-4a02-bfdf-439c3178d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Weights: [29.500102601579115, 37.698470200274926, 8.162903277866462]\n",
      "Loss: 11.428035701729321\n",
      "Update: [3.9696652890542907, -24.04154287978011, 7.475049452454584]\n",
      "New Loss 146.555636094563\n",
      "Loss v2: 20.33715811021786\n",
      "Update v2 [30.665542050554052, 43.64206064383802, 7.670587062875711]\n",
      "New Loss v2: 366.0648504872491\n"
     ]
    }
   ],
   "source": [
    "def update(w, learning_rate=10):\n",
    "    g = gradient(X, y, w)\n",
    "    for i in range(len(w)):\n",
    "        w[i] -= learning_rate * g[i] \n",
    "    return w\n",
    "\n",
    "updated_weights = update(w)\n",
    "print(\"Updated Weights:\", updated_weights) #printing the result\n",
    "\n",
    "w = [1, 1, 1]\n",
    "\n",
    "loss_new = loss(X, y, w)\n",
    "print(\"Loss:\", loss_new)\n",
    "\n",
    "update_w = update(w)\n",
    "print(\"Update:\", update_w)\n",
    "\n",
    "loss_w = loss(X, y, update_w)\n",
    "print(\"New Loss\", loss_w)\n",
    "\n",
    "\n",
    "w = [-1, -1, 0] #new values for w\n",
    "\n",
    "loss_new_2 = loss(X, y, w)\n",
    "print(\"Loss v2:\", loss_new_2)\n",
    "\n",
    "update_w_2 = update(w)\n",
    "print(\"Update v2\", update_w_2)\n",
    "\n",
    "loss_w_2 = loss(X, y, update_w_2)\n",
    "print(\"New Loss v2:\", loss_w_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea50af3-11e0-49d9-b72c-12a3d73e4bac",
   "metadata": {},
   "source": [
    "**Question:** b) Try step 6 again but use ùúÇ=10 in the ‚Äòupdate‚Äô function. Did the loss get lower this time? Explain what went wrong and why this is bad.<br>\n",
    "**Answer:** In this case the updated loss has significantly increased after using learning rate=10. If the learning rate is too high, the model never converges, but instead bounces around the weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4dee4-c634-4358-a0fc-e96ac0d63fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
