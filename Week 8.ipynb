{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e2d4a6-dc65-4ab5-b3e3-9a3871e08c6d",
   "metadata": {},
   "source": [
    "# COMP-2704: Supervised Machine Learning\n",
    "### <span style=\"color:blue\"> Week 8 </span>\n",
    "\n",
    "## <span style=\"color:blue\"> Chapter 5 continued</span>\n",
    "\n",
    "### How to find a good classifier? The perceptron algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85458f4-d1ae-4de9-aa3c-b314a0fca964",
   "metadata": {},
   "source": [
    "The pseudocode is similar for all supervised learning algorithms:\n",
    "\n",
    "1) Start with random parameters.\n",
    "2) Iterate through training data and use the error function to update the parameters.\n",
    "3) Measure error to decide when to stop training.\n",
    "\n",
    "We developed much of the code for the perceptron algorithm last week. We still need code to update the parameters during training.\n",
    "\n",
    "<img src='Fig5.21.png' width='500'/>\n",
    "\n",
    "* The 'perceptron trick' will only adjust the line when misclassified points are encountered.\n",
    "* One way a misclassification happens is when $\\hat{y} = 1$ and $y=0$.\n",
    "    * In this case the score $z = \\mathbf{w} \\cdot \\mathbf{x} + b \\ge 0$, but should be less than zero.\n",
    "* <span style=\"color:green\">**Q: How can we use a learning rate $\\eta$ to adjust $\\mathbf{w}$ and $b$ to lower $z$?**</span>\n",
    "\n",
    "    * We can adjust the bias by $b' = b - \\eta$\n",
    "    * We can adjust the weights by $\\mathbf{w}' = \\mathbf{w} - \\eta \\mathbf{x}$.\n",
    "        * Making the adjustment proportional to $\\mathbf{x}$ makes the changes bigger when $x_i$ is larger.\n",
    "        * Also, when $x_i$ is negative, this correctly makes $w_i$ larger; the goal for this case is to lower the value of $z$.\n",
    "        \n",
    "* The other misclassification case is when $\\hat{y} = 0$ and $y=1$.\n",
    "    * In this case the score $z = \\mathbf{w} \\cdot \\mathbf{x} + b < 0$, but should be greater than or equal to zero.\n",
    "    * We can adjust the bias by $b' = b + \\eta$\n",
    "    * We can adjust the weights by $\\mathbf{w}' = \\mathbf{w} + \\eta \\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c31394-7690-4673-9713-42c2f2e5852d",
   "metadata": {},
   "source": [
    "#### The perceptron trick \n",
    "* Here we develop a function to update the weights and bias when a point is misclassified.  \n",
    "* We will write this to work in general, and not just for the alien planet example we are considering.  \n",
    "* The pseudocode is:\n",
    "    * *Input*: weights $\\mathbf{w}$, bias $b$, features of a sample $\\mathbf{x}$, a label $y$, learning rate with default value $\\eta = 0.01$.\n",
    "    * *Output*: updated weights $\\mathbf{w}$ and bias $b$.\n",
    "    * *Procedure*:\n",
    "        * Find the prediction $\\hat{y}$\n",
    "        * If $\\hat{y}=1$ and $y=0$:\n",
    "            * $\\mathbf{w}' = \\mathbf{w} - \\eta \\mathbf{x}$\n",
    "            * $b' = b - \\eta$\n",
    "        * If $\\hat{y}=0$ and $y=1$:\n",
    "            * $\\mathbf{w}' = \\mathbf{w} + \\eta \\mathbf{x}$\n",
    "            * $b' = b + \\eta$\n",
    "        * Return $\\mathbf{w}'$ and bias $b'$\n",
    "            \n",
    "* Let's write this function in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948e7ffe-8ffc-425c-9963-69a0a36caedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction = -2\n",
      "original parameters: w = [1 2] \tb = -4\n",
      "updated parameters:  w = [1 2] \tb = -4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([1, 2])\n",
    "b = -4\n",
    "\n",
    "def predict(w, b, x):\n",
    "    return w.dot(x) + b\n",
    "\n",
    "def step(z):\n",
    "    return 1 if z >=0 else 0\n",
    "\n",
    "def trick_1(w, b, x, y, eta = 0.01):\n",
    "    # add code here\n",
    "    return w, b\n",
    "    \n",
    "# test the code using the data below\n",
    "x = np.array([0, 1])\n",
    "y = 1\n",
    "\n",
    "print('prediction =', predict(w, b, x))\n",
    "print('original parameters: w =', w, '\\tb =', b)\n",
    "w, b = trick_1(w, b, x, y)\n",
    "print('updated parameters:  w =', w, '\\tb =', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3813697-b4a7-463d-988d-f7f54dda7c8b",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Q: Can you improve the code for trick_1 so that it does not require a conditional?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f759bb-5abd-46ca-9da8-8d8f680317b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction = -2\n",
      "original parameters: w = [1 2] \tb = -4\n",
      "updated parameters:  w = [1 2] \tb = -4\n"
     ]
    }
   ],
   "source": [
    "def trick_2(w, b, x, y, eta = 0.01):\n",
    "    # add code here\n",
    "    return w, b\n",
    "\n",
    "# test the code using the data below\n",
    "x = np.array([0, 1])\n",
    "y = 1\n",
    "\n",
    "print('prediction =', predict(w, b, x))\n",
    "print('original parameters: w =', w, '\\tb =', b)\n",
    "w, b = trick_2(w, b, x, y)\n",
    "print('updated parameters:  w =', w, '\\tb =', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b1c94-a178-4231-93dd-d6c0912da136",
   "metadata": {},
   "source": [
    "* The above 'trick' is used for gradient descent. The error will (usually) be lower for the updated parameters.\n",
    "* You will complete the perceptron algorithm code in this week's exercise.\n",
    "* You will use the Turi Create implementation in this week's lab.\n",
    "\n",
    "<span style=\"color:red\">*Let us now review the textbook code Coding_perceptron_algorithm.ipynb.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12965721-5711-45e8-a781-5f7c6c71d70f",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Chapter 7 </span>\n",
    "### How do you measure classification models? Accuracy and its friends\n",
    "\n",
    "<img src='cartoon7.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d91f49-f88f-4b97-aa92-4fb8de4577bf",
   "metadata": {},
   "source": [
    "* A simple and important metric for classification is **accuracy**: the percentage of predictions that are correct.\n",
    "* However, as suggested by the cartoon above, accuracy is often not the best metric to use.\n",
    "* We now disucss several metrics to use for classification using two examples use cases: coronavirus and spam detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68422ac3-cd96-432e-b3a1-8a33c7208fba",
   "metadata": {},
   "source": [
    "**Medical dataset: A set of patients diagnosed with coronavirus**\n",
    "* 1,000 patients in total\n",
    "* 10 have been diagnosed with coronavirus\n",
    "* 990 have been diagnosed as healthy\n",
    "* labels are “sick” (1) or “healthy” (0) corresponding to the diagnosis\n",
    "* goal of a model would be to predict the diagnosis based on the features of each patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc86a4-1fad-4e12-8bd6-b93ad4de16f3",
   "metadata": {},
   "source": [
    "**Email dataset: A set of emails labeled spam or ham**\n",
    "* 100 emails in total\n",
    "* 40 are spam\n",
    "* 60 are ham\n",
    "* labels are 'spam' (1) or 'ham' (0)\n",
    "* goal of a model would be to predict the label based on the features of each email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822758b6-6eb0-4197-b000-c7388a5b75f6",
   "metadata": {},
   "source": [
    "### A super effective yet super useless model\n",
    "* First, let's look at the medical dataset.\n",
    "* As in the cartoon above, consider a model 1 that predicts everyone as healthy.\n",
    "* All 1000 patients are predicted healthy (0)\n",
    "* We calculate $\\mbox{accuracy} = \\frac{990}{1000} = 99\\%$\n",
    "\n",
    "<span style=\"color:green\">**Q: Is this a good model?**</span>\n",
    "\n",
    "* Even though accuracy is high, this is a bad model.\n",
    "* To develop better metrics, we need to look into the predictions for each class.\n",
    "* Predictions can be correct or incorrect for each class, so there are four numbers to consider in binary classification:\n",
    "    * *True positive*  (TP): label is 1 and prediction is 1\n",
    "    * *False positive* (FP): label is 0 and prediction is 1\n",
    "    * *True negative*  (TN): label is 0 and prediction is 0\n",
    "    * *False negative* (FN): label is 1 and prediction is 0\n",
    "* These are often presented in a table called the **confusion matrix**:\n",
    "\n",
    "<img src='confusion.png' width='400'/>\n",
    "\n",
    "* By combining these numbers in different ways, we can find other metrics to choose from.\n",
    "* Depending on the use case, one type of error may be worse than the other, or they may be similarly bad.\n",
    "* One should choose metrics that are most relevant to the use case.\n",
    "\n",
    "For the coronavirus model 1 that predicts everyone as healthy, we get:\n",
    "\n",
    "<img src='table7.2.png' width='600'/>\n",
    "\n",
    "<span style=\"color:green\">**Q: Which is worse here, a false negative or a false positive?**</span>\n",
    "\n",
    "* The worst mistake is a *false negative*, predicting a patient is healthy when they are sick and need care.\n",
    "* A false positive would result in a patient getting extra care that is not needed, which is not nearly as bad.\n",
    "* For a use case where false negatives must be avoided, we define **recall**: Among the positive examples, how many did we correctly classify? \n",
    "$$ R = \\frac{\\mbox{TP}}{\\mbox{TP} + \\mbox{FN}} $$\n",
    "* $R \\in [0, 1]$ and higher values are better than lower values.\n",
    "* For coronavirus model 1, we find $R = \\frac{0}{10} = 0$, telling us how bad the model is.\n",
    "* Consider coronavirus model 2, with the confusion matrix\n",
    "<img src='table7.3.png' width='600'/>\n",
    "\n",
    "* Model 2 seems better, because it has fewer false negatives.\n",
    "\n",
    "<span style=\"color:green\">**Q: What is the recall of model 2? What is the accuracy? Which model do you think is better?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546a585-5277-4555-9f67-e7631b18977b",
   "metadata": {},
   "source": [
    "Let us now turn to the spam detection use case. Consider the following two models:\n",
    "<img src='table7.4.png' width='600'/>\n",
    "<img src='table7.5.png' width='550'/>\n",
    "\n",
    "They are both $85\\%$ accurate, but which is better?\n",
    "\n",
    "<span style=\"color:green\">**Q: Which problem is worse in spam detection, false positives or false negatives?**</span>\n",
    "\n",
    "* In spam detection, you must never delete ham, so *false positves* are a serious problem.\n",
    "* False negatives result in spam getting in the inbox, which is not as bad.\n",
    "* The metric we define for this case is **precision**: Among the examples we classified as positive, how many did we correctly classify? $$ P = \\frac{ \\mbox{TP}}{\\mbox{TP} + \\mbox{FP}} $$\n",
    "* $P \\in [0, 1]$ and higher values are better than lower values.\n",
    "* For the models above we find $P_1 = \\frac{30}{35} \\approx 0.857$ and $P_2 = \\frac{35}{45} \\approx 0.777$, showing that model 1 does a better job of avoiding false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d3a88-7491-4cfc-8aff-ec67345ca141",
   "metadata": {},
   "source": [
    "### Combining recall and precision as a way to optimize both: The $F_\\beta$-score\n",
    "* Precision and recall can be combined in a way that makes both important; this is the $F_\\beta$ score: $$ F_\\beta = \\frac{(1+\\beta^2)PR}{\\beta^2P + R} $$\n",
    "* Notice this is zero if either $P$ or $R$ is zero.\n",
    "* $\\beta \\in [0, \\infty)$ is a number that you can choose.\n",
    "* $\\beta = 1$ weights $P$ and $R$ equally.\n",
    "* $\\beta > 1$ places more importance on recall and avoiding false negatives.\n",
    "* $0 < \\beta < 1$ places more importance on precision and avoiding false positives.\n",
    "* For example, we might consider $\\beta = 2$ for the coronavirus model; we might consider $\\beta = 0.5$ for the spam detection model.\n",
    "\n",
    "<span style=\"color:green\">**Q: What is the $F_2$ score for the spam detection models? What are the $F_{0.5}$ scores?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9425c3d7-8c68-4c72-a241-6d1d4585a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_beta(TP, FP, TN, FN, beta=1):\n",
    "    # write this code\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db400cb-8594-420c-ba0e-b2e18e9c6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# find results here\n",
    "print(F_beta(TP=1, FP=1, TN=1, FN=1, beta=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698be18-aa83-4089-8080-21b7c4dff190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
